\thispagestyle{fancy}
\addtocontents{toc}{\cftpagenumberson{chapter}}
\addcontentsline{toc}{chapter}{ABSTRACT}
\begin{center}
\large\bfseries ABSTRACT\\
\end{center}
\noindent Andrew Mahisa Halim (00000005171)\\

\noindent {\bfseries\large DEEP REINFORCEMENT LEARNING FOR GAMES USING ADAM-DQL (DEEP Q-LEARNING)} \\
\noindent Thesis, Faculty of Science and Technology (2018). \\
\begin{singlespace}

\noindent (xiii + 75 pages, 2 tables, 28 figures, 7 algorithms, 1 appendix)\\

The field of deep learning has gained a huge traction over the last few years. Its youngest sub-field, Deep Reinforcement learning (RL) has shown remarkable potential for artificial intelligent based opponent in games. Several research based on Deep RL begun to appear and ultimately lead to the development of Deep Q-Learning, a deep learning technique that allows an agent to learn from an image without the help of human-created model or features. 
\par
 Since Deep Q-Learning (DQL) is still in its early stages, it was mostly tested on simple, \textit{toy-like} examples. This thesis will try to take a step further and apply deep reinforcement learning to complex games. This will be achieved by combining classical DQL with Adam optimizer, and several policy improvement techniques. This thesis also introduced partial training, a policy improvement technique for neural network that kickstarts an agent to get rewards faster in complex games.  
\par

 Adam-DQL agent is then tested on game environments based on real life video games. The results indicate that Adam-DQL agent is learns faster and performs significantly better compared to classical Deep Q-Learning. We further shows that combined with partial training, Adam-DQL is viable to solve even really complex games. 
 
 
 
\vspace{5mm}
\noindent Keywords: deep reinforcement learning, Adam, video games, convolutional neural networks, partial training, demonstration. \\ \\
\noindent References: 30 (1981-2017)\\
\end{singlespace}